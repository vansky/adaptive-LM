# Adaptive-LM

**Note**: This repository is deprecated. All functionality has been merged into the [Neural Complexity](https://github.com/vansky/neural-complexity) repo along with better documentation.

A neural language model that updates its training weights after each test observation in order to better adapt to the test domain, hopefully in a similar fashion to humans in laboratory settings (Fine et al., 2013; Fine and Jaeger, 2016).

Fine, A. B., Jaeger, T. F., Farmer, T. A, and Qian, T. (2013). Rapid expectation adaptation during syntactic comprehension. PLoS ONE.

Fine, A. B. and Jaeger, T. F. (2016). The role of verb repetition in cumulative syntactic priming in comprehension. Journal of Experimental Psychology: Learning, Memory & Cognition.
