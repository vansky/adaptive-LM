# Adaptive-LM

A neural language model that updates its training weights after each test observation in order to better adapt to the test domain, hopefully in a similar fashion to humans in laboratory settings (Fine et al., 2013; Fine and Jaeger, 2016).

**Note**: This repository will soon be merged with the [Neural Complexity](https://github.com/vansky/neural-complexity) repo. Check that repo for documentation.

Fine, A. B., Jaeger, T. F., Farmer, T. A, and Qian, T. (2013). Rapid expectation adaptation during syntactic comprehension. PLoS ONE.

Fine, A. B. and Jaeger, T. F. (2016). The role of verb repetition in cumulative syntactic priming in comprehension. Journal of Experimental Psychology: Learning, Memory & Cognition.
